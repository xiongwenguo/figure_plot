{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ebd1f94-3d64-48c2-9b9a-1a13fcdffecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils,AutoConfig\n",
    "from bertviz import model_view,head_view\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "import argparse,torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11209e9e-54cb-486d-b2fe-d235312ba2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\") \n",
    "from uer.utils.tokenizers import BertTokenizer\n",
    "from uer.utils.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "564136a5-5f6e-47f8-8c39-28c403ae66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS:\n",
    "    def __init__(self, d):\n",
    "        for k, v in d.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c2f0c62-dac7-4bd7-a99c-0e0af417a81f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_text = \"4500 0000 003c 3c99 9902 0240 4000 003f 3f06 06e1 e1eb ebc6 c6df df63 63e1 e114 14d0 d095 95cf cff7 f7e5 e5f9 f9de de56 56b5 b5df df1a 1a00 0000 0000 0000 00a0 a002 02ff ffff ff2a 2ac0 c000 0000 0002 0204 0405 0550 5004 0402 0208 080a 0a00 00d3 d346 4618 1800 0000 0000 0000 0001 0103 0303 0306 4500 0000 003c 3c00 0000 0040 4000 0040 4006 0679 79ee ee14 14d0 d095 95cf cfc6 c6df df63 63e1 e1f9 f9de def7 f7e5 e520 2006 06b2 b247 4756 56b5 b5df df1b 1ba0 a012 1271 7120 2011 11c9 c900 0000 0002 0204 0405 05b4 b404 0402 0208 080a 0a87 87a6 a64d 4d6c 6c00 00d3 d346 4618 1801 0103 0303 0307 4500 0000 0034 3499 9903 0340 4000 003f 3f06 06e1 e1f2 f2c6 c6df df63 63e1 e114 14d0 d095 95cf cff7 f7e5 e5f9 f9de de56 56b5 b5df df1b 1b20 2006 06b2 b248 4880 8010 1004 04fb fbac acb1 b100 0000 0001 0101 0108 080a 0a00 00d3 d346 4621 2187 87a6 a64d 4d6c 4500 0000 00e8 e899 9904 0440 4000 003f 3f06 06e1 e13d 3dc6 c6df df63 63e1 e114 14d0 d095 95cf cff7 f7e5 e5f9 f9de de56 56b5 b5df df1b 1b20 2006 06b2 b248 4880 8018 1804 04fb fb50 50ea ea00 0000 0001 0101 0108 080a 0a00 00d3 d346 4622 2287 87a6 a64d 4d6c 6c16 1603 0301 0100 00af af01 0100 0000 00ab ab03 0303 0340 4500 0000 0034 34ff ffcc cc40 4000 0040 4006 067a 7a29 2914 14d0 d095 95cf cfc6 c6df df63 63e1 e1f9 f9de def7 f7e5 e520 2006 06b2 b248 4856 56b5 b5df dfcf cf80 8010 1000 00eb ebaf aff4 f400 0000 0001 0101 0108 080a 0a87 87a6 a64d 4d84 8400 00d3 d346 4622\"  \n",
    "config = AutoConfig.from_pretrained(\"../models/bert/base_config2.json\",output_attentions=True)\n",
    "model = AutoModel.from_pretrained(\"../models/finetuned_model_android.bin\", config=config)  # Configure model to return attention values\n",
    "args = {\"vocab_path\":\"../models/encryptd_vocab.txt\",\"spm_model_path\":None,\"seq_length\":320}\n",
    "args = ARGS(args)\n",
    "tokenizer = BertTokenizer(args)\n",
    "src = tokenizer.convert_tokens_to_ids([CLS_TOKEN] +tokenizer.tokenize(input_text))\n",
    "if len(src) > args.seq_length:\n",
    "    src = src[: args.seq_length]\n",
    "while len(src) < args.seq_length:\n",
    "    src.append(0)\n",
    "# inputs = {}\n",
    "# inputs['input_ids'] = torch.tensor([src])\n",
    "# inputs['token_type_ids'] = torch.tensor([[0]*len(src)])\n",
    "# inputs['attention_mask'] = torch.tensor([[1]*len(src)])\n",
    "inputs = torch.tensor([src])\n",
    "# print(inputs)\n",
    "outputs = model(inputs)  # Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce8c623f-2e8b-4f57-9f8c-dfe993cee478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The attention tensor does not have the correct number of dimensions. Make sure you set output_attentions=True when initializing your model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m attention \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Retrieve attention from model outputs\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_ids_to_tokens(inputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist())  \u001b[38;5;66;03m# Convert input ids to token strings\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mhead_view\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhtml_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreturn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Display model view\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# html_head_view = head_view(attention, tokens, html_action='return')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# with open(\"bert.html\", 'w') as file:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     file.write(html_head_view.data)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bertviz/head_view.py:63\u001b[0m, in \u001b[0;36mhead_view\u001b[0;34m(attention, tokens, sentence_b_start, prettify_tokens, layer, heads, encoder_attention, decoder_attention, cross_attention, encoder_tokens, decoder_tokens, include_layers, html_action)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_layers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     include_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(num_layers(attention)))\n\u001b[0;32m---> 63\u001b[0m attention \u001b[38;5;241m=\u001b[39m \u001b[43mformat_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sentence_b_start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     attn_data\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     66\u001b[0m         {\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m         }\n\u001b[1;32m     72\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bertviz/util.py:11\u001b[0m, in \u001b[0;36mformat_attention\u001b[0;34m(attention, layers, heads)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_attention \u001b[38;5;129;01min\u001b[39;00m attention:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# 1 x num_heads x seq_len x seq_len\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_attention\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe attention tensor does not have the correct number of dimensions. Make sure you set \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_attentions=True when initializing your model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     layer_attention \u001b[38;5;241m=\u001b[39m layer_attention\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m heads:\n",
      "\u001b[0;31mValueError\u001b[0m: The attention tensor does not have the correct number of dimensions. Make sure you set output_attentions=True when initializing your model."
     ]
    }
   ],
   "source": [
    "attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0].numpy().tolist())  # Convert input ids to token strings\n",
    "head_view(attention, tokens,include_layers=[11], include_heads=[2])  # Display model view\n",
    "# html_head_view = head_view(attention, tokens, html_action='return')\n",
    "\n",
    "# with open(\"bert.html\", 'w') as file:\n",
    "#     file.write(html_head_view.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c3a813b1-8f9b-43e3-b286-c860b4caf3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0021, 0.0022, 0.0028,  ..., 0.0032, 0.0025, 0.0027],\n",
      "        [0.0027, 0.0019, 0.0027,  ..., 0.0031, 0.0036, 0.0026],\n",
      "        [0.0027, 0.0018, 0.0033,  ..., 0.0036, 0.0034, 0.0028],\n",
      "        ...,\n",
      "        [0.0027, 0.0021, 0.0033,  ..., 0.0026, 0.0031, 0.0029],\n",
      "        [0.0027, 0.0019, 0.0031,  ..., 0.0038, 0.0027, 0.0024],\n",
      "        [0.0020, 0.0022, 0.0028,  ..., 0.0033, 0.0026, 0.0029]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(attention[-1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54461c82-4576-46cd-a11c-92e64600cddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb62f2-a2b4-4f0e-9935-48e912802b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
